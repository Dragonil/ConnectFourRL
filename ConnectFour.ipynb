{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Connect Four "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our Project is an AI that plays the game [ConnectFour](https://en.wikipedia.org/wiki/Connect_Four)\n",
    "\n",
    "### Authors\n",
    "\n",
    "- Oliver Gorges\n",
    "- Fabian StÃ¶lzle\n",
    "\n",
    "### Challenges\n",
    "\n",
    "There are [4531985219092](https://oeis.org/A212693) possible states in the game ConnectFour with a 6x7 grid\n",
    "\n",
    "    This Results in:\n",
    "        - A very large set of possible States, which is nearly impossible to discover completely\n",
    "        - A lot of time to train the AI til it discovered enough states to play against a real Player\n",
    "        - A lot of storage space is needed to store the Action-Value Function\n",
    "    \n",
    "\n",
    "\n",
    "### How to Play\n",
    "\n",
    "#### Train the AI\n",
    "\n",
    "Before you can play the game against the AI you should train it at least for `1000000` episodes.\n",
    "\n",
    "> To play the game without trainig you can also download a [JSON](drive.google.com/file/d/1aWwLZWc6jVqUtHLk88wz48rknHi-ohjI/view?usp=sharing) with trained Data.\n",
    "> This will not work with Jupyter notebook\n",
    "\n",
    "#### Start the Game\n",
    "\n",
    "To play the game against the ai, you have to change the `play` parameter in the `Game Configuration` to True \n",
    "\n",
    "When you run now the project it will print the playing Field and you can start playing the game\n",
    "```bash\n",
    "    [['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' 'O' '-' '-' '-']]\n",
    "    -------------------------------\n",
    "    [['1' '2' '3' '4' '5' '6' '7']]\n",
    "    Player 2, Enter Postion (1-7): \n",
    "```\n",
    "> When you use oldData it can take a while to load the trained data and display the gamefield\n",
    "\n",
    "> In the current state of the Project you start always as the secound player, so the ai has done its first turn already.\n",
    "\n",
    "#### Game Rules\n",
    "\n",
    "##### Inputs\n",
    "\n",
    "The player can input a number between 1 and the configured amount of columns (`columns_count`, Default: 7). \n",
    "This will place a stone in the first empty row in the selected column.\n",
    "\n",
    "##### Goal\n",
    "\n",
    "To win the game you have to create a row out of four stones in a Horizontal, Vertical or Diagonal direction.\n",
    "\n",
    "```bash\n",
    "    Horizontal Win\n",
    "    [['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' 'O' '-' '-' '-']\n",
    "     ['-' '-' '-' 'O' '-' '-' '-']\n",
    "     ['-' '-' 'X' 'O' '-' '-' '-']\n",
    "     ['-' '-' 'X' 'O' '-' '-' 'X']]\n",
    "    -------------------------------\n",
    "    [['1' '2' '3' '4' '5' '6' '7']]\n",
    "    Player 2, Enter Postion (1-7): \n",
    "```\n",
    "\n",
    "```bash\n",
    "    Vertical Win\n",
    "    [['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' 'X' 'X' '-' '-']\n",
    "     ['-' 'O' 'O' 'O' 'O' 'X' '-']]\n",
    "    -------------------------------\n",
    "    [['1' '2' '3' '4' '5' '6' '7']]\n",
    "    Player 2, Enter Postion (1-7): \n",
    "```\n",
    "\n",
    "```bash\n",
    "    Diagonal Win\n",
    "    [['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' '-']\n",
    "     ['-' '-' '-' '-' '-' '-' 'O']\n",
    "     ['-' '-' '-' '-' '-' 'O' 'X']\n",
    "     ['-' '-' '-' '-' 'O' 'X' 'X']\n",
    "     ['-' '-' 'O' 'O' 'X' 'O' 'X']]\n",
    "    -------------------------------\n",
    "    [['1' '2' '3' '4' '5' '6' '7']]\n",
    "    Player 2, Enter Postion (1-7): \n",
    "```\n",
    "\n",
    "> The amount of stones to win can be changed by changing the parameter `terminating_length`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Game Configuration\n",
    "\n",
    "To use a alredy trained Action-Value function set useOld to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play = True\n",
    "useOld = False\n",
    "rows_count = 6\n",
    "columns_count = 7\n",
    "terminating_length = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = 0 \n",
    "p = 1\n",
    "players = ['O','X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Initialize AI Parameters\n",
    "\n",
    "The high e value is needed to explore in the beginning as much as possible states, it can be lowered after around 1-2 Million episodes when there are enough states discovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "e = 0.4\n",
    "alpha = 0.1\n",
    "gamma = 1\n",
    "columns = np.arange(columns_count)\n",
    "actionQ = {}\n",
    "episodes = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rStep = 0\n",
    "rDraw = -10\n",
    "rLose = -100\n",
    "rWin = 100\n",
    "rInvalid = -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play Configuration\n",
    "\n",
    "changes the exploration rate to 0 and use trained data to play against a real player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if play:\n",
    "    ## useOld = True ## Use not in Jupyter\n",
    "    e = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trained AI\n",
    "\n",
    "Load existing State-Action-Value function from Json\n",
    "\n",
    "> Doesnt work in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(useOld):\n",
    "    try:\n",
    "        actionQ = json.load(open('actionQ.json'))\n",
    "        print('old ActionQ loaded')\n",
    "    except IOError:\n",
    "        print('no old data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### End Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "## Recrusive function to check if there is a row of stones\n",
    "def checkPos(field, pos, player, mv, stw):\n",
    "    if(stw < 1): \n",
    "        return True ## Stops when reaching the Terminating Length\n",
    "    if (pos[0] < 0 or pos[0] >= rows_count) or (pos[1] < 0 or pos[1] >= columns_count):\n",
    "        return False ## Stops when reaching the end of the Gamefield\n",
    "    if(field[pos[0]][pos[1]] != player):\n",
    "        return False ## Stops when finding a value that is not the player \n",
    "    return True and checkPos(field, (pos[0]+mv[0], pos[1]+mv[1]), player, mv, stw - 1) ## checks the next position\n",
    "\n",
    "\n",
    "def winningConditions(field, player):\n",
    "    for r in range(rows_count):\n",
    "        for c in range(columns_count):\n",
    "            if(field[r][c] == player):\n",
    "                if(checkPos(field, (r, c), player, (1, 0), terminating_length)): # Horizontal\n",
    "                    #print(\"H\")\n",
    "                    return True\n",
    "                if(checkPos(field, (r, c), player, (0, 1), terminating_length)): # Vertical\n",
    "                    #print(\"V\")\n",
    "                    return True\n",
    "                if(checkPos(field, (r, c), player, (-1,1), terminating_length)): # Diagonal Left\n",
    "                    #print(\"DL\")\n",
    "                    return True\n",
    "                if(checkPos(field, (r, c), player, (1,1), terminating_length)): # Diagonal Right\n",
    "                    #print(\"DR\")\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def draw(field): ## Checks if there are an empty position in the Gamefield\n",
    "    for r in range(rows_count):\n",
    "        for c in range(columns_count):\n",
    "            if field[r][c] == -1:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot\n",
    "\n",
    "Random player to train our AI\n",
    "\n",
    "He has some logic to finish a game in vertical or horizontal when it is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trainer(field):\n",
    "    col = -1\n",
    "    ## Strategy to finish the game when it has a row of stones that is one smaller than the terminating length\n",
    "    for r in range(rows_count):\n",
    "        for c in range(columns_count):\n",
    "            if(field[r][c] == p):\n",
    "                if(checkPos(field, (r, c), p, (1, 0), terminating_length-1)): # Horizontal\n",
    "                    if r-1 >= 0:\n",
    "                        if field[r-1][c] == -1:\n",
    "                            col = c\n",
    "                            break\n",
    "                if(checkPos(field, (r, c), p, (0, 1), terminating_length-1)): # Vertical\n",
    "                    if c-1 >= 0:\n",
    "                        if field[r][c-1] == -1:\n",
    "                            col = c-1\n",
    "                            break\n",
    "                    if c+terminating_length-1 < columns_count:\n",
    "                        if field[r][c+terminating_length-1] == -1:\n",
    "                            col = c + terminating_length-1\n",
    "                            break\n",
    "    weights = np.full(columns_count, 1)\n",
    "    if col >= 0 and col < columns_count:\n",
    "        weights[col] = 7 ## Possibility to Finish the game when its possible \n",
    "    return random.choices(columns, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Game Funcions\n",
    "\n",
    "Because the gamefield represents our state we used a hash of our field to save storagespace in our Action-Value function\n",
    "\n",
    "> There are [4531985219092](https://oeis.org/A212693) possible states in the game ConnectFour with a 6x7 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def placeStone(field, column, player):\n",
    "    for r in reversed(range(rows_count)):\n",
    "        if(field[r][column] == -1):\n",
    "            field[r][column] = player\n",
    "            return True\n",
    "    return False # row is full\n",
    "\n",
    "## Displays the Gamefield for the Player\n",
    "def printField(field):\n",
    "    nField = np.chararray((rows_count, columns_count), itemsize=1, unicode=True)\n",
    "    numbers = np.chararray((1, columns_count), itemsize=1, unicode=True)\n",
    "    for r in range(rows_count):\n",
    "        for c in range(columns_count):\n",
    "            if(field[r][c] != -1):\n",
    "                nField[r][c] = players[field[r][c]]\n",
    "            else:\n",
    "                nField[r][c] = '-'\n",
    "    for c in range(columns_count):\n",
    "        numbers[0][c] = str(c+1)\n",
    "    print(nField)\n",
    "    print('-' * (columns_count * 5) )\n",
    "    print(numbers)\n",
    "\n",
    "## Creates a Hash String for the current Gamefield\n",
    "def hashField(field):\n",
    "    return hashlib.sha1(field).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player 2\n",
    "\n",
    "Player 2 is part if the environment in the perspective of our AI, it can be represented by the random Trainer or a real Player.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opponentTurn(field, p, ai):\n",
    "    \n",
    "    ## Checks if AI Wins\n",
    "    if (winningConditions(field, ai)):\n",
    "        return rWin  # AI Winns\n",
    "    if (draw(field)):\n",
    "        return rDraw\n",
    "    \n",
    "    if not play: ## Random Player\n",
    "        while True:\n",
    "            if (placeStone(field, Trainer(field), p)):\n",
    "                break\n",
    "    else: ## Real Player\n",
    "        printField(field)\n",
    "        while True:\n",
    "            try:\n",
    "                column = int(input('Player ' + str(p+1) + ', Enter Postion (1-' + str(columns_count)+'): '))\n",
    "                if (column > 0 and column <= columns_count):\n",
    "                    column -= 1 ## Correct input for Array\n",
    "                    if (placeStone(field, column, p)):\n",
    "                        break\n",
    "                    print('Invalid Input')\n",
    "                print('Only Numbers between 1 and ' + str(columns_count))\n",
    "            except ValueError:\n",
    "                print('Only Numbers')\n",
    "                continue\n",
    "\n",
    "\n",
    "    ## Checks if Player Wins\n",
    "    if (winningConditions(field, p)):\n",
    "        return rLose  # Player Winns\n",
    "    if (draw(field)):\n",
    "        return rDraw\n",
    "    return rStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e-Greedy\n",
    "\n",
    "If there are several max values we chose randomly one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def policyDecideColumn(hState, actionQ):\n",
    "    weights = np.full(len(columns), e / len(columns))\n",
    "    ## Check if we know the state already\n",
    "    if hState in actionQ:\n",
    "        if play:\n",
    "            print(actionQ[hState])\n",
    "        result = np.argwhere(actionQ[hState] == np.amax(actionQ[hState])) ## get a Subset with the index of the lages values\n",
    "        bestColumn = random.choice(result)[0] ## chooses a random value from the subset when there are multible maxValues\n",
    "        weights[bestColumn] += 1 - e ## Set weight for the BestColumn to exploit the State\n",
    "    col = random.choices(columns, weights) ## chooses the final column based on the weights (exploration, exploitation)\n",
    "    return col[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### TD(0)\n",
    "\n",
    "Why TD(0)\n",
    "- don't need to discover hole state set\n",
    "- can improve during episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def playGame():\n",
    "    field = np.full((rows_count, columns_count), -1)\n",
    "    column = policyDecideColumn(hashField(field), actionQ)\n",
    "    while True:\n",
    "        oldField = np.copy(field) ## S\n",
    "        oldColumn = column ## A\n",
    "        if (placeStone(field, oldColumn, ai)):  ## Take Action\n",
    "            reward = opponentTurn(field, p, ai) ## Reward\n",
    "            hState = hashField(field) ## S'\n",
    "            if not ( hState in actionQ): ## creates empty state if it not exists\n",
    "                actionQ[hState] = np.zeros(columns_count).tolist()\n",
    "\n",
    "        else:  ## Invalid Action\n",
    "            reward = rInvalid ## Negative reward when it trys to choose a full row\n",
    "\n",
    "        column = policyDecideColumn(hashField(field), actionQ) ## A'\n",
    "\n",
    "        hOldState = hashField(oldField)\n",
    "        hState = hashField(field)\n",
    "        if hOldState in actionQ and hState in actionQ:\n",
    "            ## Calculate new Value for the last State\n",
    "            actionQ[hOldState][oldColumn] = actionQ[hOldState][oldColumn] + alpha * (\n",
    "                    reward + gamma * actionQ[hState][column] - actionQ[hOldState][oldColumn])\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "        if reward > rStep or reward <= rDraw:\n",
    "            # stops game when someone Wins\n",
    "            return reward, field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Start State\n",
    "\n",
    "When there are no values in the Action-Value Function we set the empty gamefield as a inital state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(actionQ) == 0:\n",
    "    field = np.full((rows_count, columns_count), -1)\n",
    "    actionQ[hashField(field)] = np.zeros(columns_count).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = 0\n",
    "drw = 0\n",
    "win = 1\n",
    "lose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Train AI / Play Game\n",
    "\n",
    "In this part we can play the game against the trained AI or iterate through the episodes to train the AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' '-']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 7\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 2\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' '-']\n",
      " ['O' 'X' '-' '-' 'O' '-' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 3\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' 'O']\n",
      " ['O' 'X' 'X' '-' 'O' '-' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 7\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' 'X']\n",
      " ['O' '-' '-' '-' '-' '-' 'O']\n",
      " ['O' 'X' 'X' '-' 'O' '-' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 7\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' 'X']\n",
      " ['O' '-' '-' '-' '-' '-' 'X']\n",
      " ['O' '-' '-' '-' '-' '-' 'O']\n",
      " ['O' 'X' 'X' '-' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 1\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['X' '-' '-' '-' '-' '-' 'X']\n",
      " ['O' '-' '-' '-' '-' '-' 'X']\n",
      " ['O' '-' '-' '-' '-' '-' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 2\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['X' '-' '-' '-' '-' '-' 'X']\n",
      " ['O' '-' '-' '-' '-' '-' 'X']\n",
      " ['O' 'X' '-' '-' 'O' '-' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 2\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['X' 'O' '-' '-' '-' '-' 'X']\n",
      " ['O' 'X' '-' '-' '-' '-' 'X']\n",
      " ['O' 'X' '-' '-' 'O' '-' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 4\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' '-']\n",
      " ['X' 'O' '-' '-' '-' '-' 'X']\n",
      " ['O' 'X' '-' '-' '-' '-' 'X']\n",
      " ['O' 'X' '-' 'X' 'O' '-' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 5\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' '-']\n",
      " ['X' 'O' '-' '-' '-' '-' 'X']\n",
      " ['O' 'X' '-' '-' 'X' '-' 'X']\n",
      " ['O' 'X' 'O' 'X' 'O' '-' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 6\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['-' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' '-']\n",
      " ['X' 'O' '-' '-' 'O' '-' 'X']\n",
      " ['O' 'X' '-' '-' 'X' '-' 'X']\n",
      " ['O' 'X' 'O' 'X' 'O' 'X' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 6\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[['O' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' '-']\n",
      " ['X' 'O' '-' '-' 'O' '-' 'X']\n",
      " ['O' 'X' '-' '-' 'X' 'X' 'X']\n",
      " ['O' 'X' 'O' 'X' 'O' 'X' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Player 2, Enter Postion (1-7): 6\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "You Win\n",
      "[['O' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' '-']\n",
      " ['X' 'O' '-' '-' 'O' 'X' 'X']\n",
      " ['O' 'X' '-' '-' 'X' 'X' 'X']\n",
      " ['O' 'X' 'O' 'X' 'O' 'X' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n",
      "Restart? (y/n): n\n",
      "Result:\n",
      "14\n",
      "[['O' '-' '-' '-' '-' '-' '-']\n",
      " ['O' '-' '-' '-' '-' '-' '-']\n",
      " ['X' 'O' '-' '-' 'O' 'X' 'X']\n",
      " ['O' 'X' '-' '-' 'X' 'X' 'X']\n",
      " ['O' 'X' 'O' 'X' 'O' 'X' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'X']]\n",
      "-----------------------------------\n",
      "[['1' '2' '3' '4' '5' '6' '7']]\n"
     ]
    }
   ],
   "source": [
    "if play:\n",
    "    while True:\n",
    "        rwd, field = playGame()\n",
    "        if rwd < rDraw:\n",
    "            print('You Win')\n",
    "        if rwd > rStep:\n",
    "            print('You Loose')\n",
    "        printField(field)\n",
    "        if not (input('Restart? (y/n): ') == 'y'):\n",
    "            break\n",
    "else:\n",
    "    for i in range(episodes):\n",
    "        newReward, field = playGame()\n",
    "        if newReward == -10:\n",
    "            drw += 1\n",
    "        if newReward == -100:\n",
    "            lose += 1\n",
    "        if newReward == 100:\n",
    "            win += 1\n",
    "        # reward += newReward1\n",
    "        if i % 10000 == 0:\n",
    "            print(len(actionQ)-last)\n",
    "            print(str(i/episodes*100) + '%')\n",
    "            print('Draw: ' + str(drw) + ' Win/Lose ' + str(win/lose))\n",
    "            last = len(actionQ)\n",
    "            # e -= 0.001\n",
    "            #value = actionQ.values()\n",
    "            #print (key, end=' => ')\n",
    "            #print(value)\n",
    "            #print(i)\n",
    "        if i > 999999:\n",
    "            play = True\n",
    "            e = 0\n",
    "\n",
    "print(\"Result:\")\n",
    "print(len(actionQ))\n",
    "printField(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save ActionQ \n",
    "\n",
    "Saves the Action-Value function in a Json to reuse it in another session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = json.dumps(actionQ)\n",
    "f = open(\"ActionQ.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
